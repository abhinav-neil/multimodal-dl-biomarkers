{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "import shutil\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pypdf import PdfReader\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restructure tcga data folders by case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the base directory\n",
    "base_dir = '/mnt/disks/ext/data/gdc/tcga/brca/'\n",
    "# Define the pattern for the case id\n",
    "pattern = r\"TCGA-\\w{2}-\\w{4}\"\n",
    "# Iterate over all directories in the base directory\n",
    "for dirpath, dirnames, filenames in os.walk(base_dir):\n",
    "    for filename in filenames:\n",
    "        # Find the case id in the filename\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            case_id = match.group()\n",
    "            # Create a new directory for this case id, if it doesn't exist\n",
    "            new_dir = os.path.join(base_dir, case_id)\n",
    "            os.makedirs(new_dir, exist_ok=True)\n",
    "            # Move the file to the new directory\n",
    "            shutil.move(os.path.join(dirpath, filename), os.path.join(new_dir, filename))\n",
    "\n",
    "# move other folders/files, except for the case folders, to misc folder\n",
    "# Define the pattern for the case id and the 8-digit alphanumeric\n",
    "case_pattern = r\"TCGA-\\w{2}-\\w{4}\"\n",
    "misc_pattern = r\"^[a-z0-9]{8}-\"\n",
    "\n",
    "# Create the 'misc' directory if it doesn't exist\n",
    "misc_dir = os.path.join(base_dir, 'misc')\n",
    "os.makedirs(misc_dir, exist_ok=True)\n",
    "\n",
    "# Create a list to store directories to be moved\n",
    "dirs_to_move = []\n",
    "\n",
    "# Generate a list of all directories in the base directory\n",
    "all_dirs = [x[0] for x in os.walk(base_dir) if not x[0].startswith(misc_dir)]\n",
    "\n",
    "# Iterate over all directories in the list\n",
    "for dirpath in all_dirs:\n",
    "    # If the directory is empty, remove it\n",
    "    if dirpath != base_dir and not any(os.scandir(dirpath)):\n",
    "        os.rmdir(dirpath)\n",
    "    else:\n",
    "        # If the directory name starts with an 8-digit alphanumeric followed by a hyphen\n",
    "        # and it's not a case directory, add it to the list of directories to be moved\n",
    "        dirname = os.path.basename(dirpath)\n",
    "        if re.match(misc_pattern, dirname) and not re.match(case_pattern, dirname):\n",
    "            dirs_to_move.append(dirpath)\n",
    "\n",
    "# Move the directories in the list to the 'misc' directory\n",
    "for dirpath in dirs_to_move:\n",
    "    if os.path.exists(dirpath):  # Check if the directory still exists\n",
    "        dest_dir = os.path.join(misc_dir, os.path.basename(dirpath))\n",
    "        if os.path.exists(dest_dir):\n",
    "            shutil.rmtree(dest_dir)\n",
    "        shutil.move(dirpath, dest_dir)\n",
    "# count # cases in base dir\n",
    "case_count = 0\n",
    "\n",
    "# Iterate over all directories in the base directory\n",
    "for dirpath, dirnames, _ in os.walk(base_dir):\n",
    "    # If the directory name matches the case id pattern, increment the counter\n",
    "    dirname = os.path.basename(dirpath)\n",
    "    if re.match(case_pattern, dirname):\n",
    "        case_count += 1\n",
    "\n",
    "print(f\"total number of case directories: {case_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pdf to text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22745it [00:00, 51842.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "extract_text_from_pdf('/mnt/disks/ext/data/gdc/tcga/brca/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create manifest file for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of .svs files: 3110\n",
      "number of files in manifest: 597\n",
      "number of files in manifest that are in data dir: 597\n"
     ]
    }
   ],
   "source": [
    "# set data dir\n",
    "data_dir = 'tcga/brca/'\n",
    "# list all case folders in data dir (i.e. all folders that start with 'TCGA-')\n",
    "case_dirs = [f for f in os.listdir(data_dir) if isdir(join(data_dir, f)) and f.startswith('TCGA-')]\n",
    "# get list of all .svs files in each case folder\n",
    "svs_files = []\n",
    "for case_dir in case_dirs:\n",
    "    svs_files.extend([f for f in os.listdir(join(data_dir, case_dir)) if f.endswith('.svs')])\n",
    "print(f'number of .svs files: {len(svs_files)}')\n",
    "# remove '.svs' from file names\n",
    "# all_files = [f.replace('.svs', '') for f in svs_files]\n",
    " \n",
    "# compare w/ list of .svs files\n",
    "manifest_svs_path = '/home/neil/multimodal/stils/manifests/manifest_ellogon.txt'\n",
    "# manifest_files = pd.read_csv(manifest_svs_path, sep='\\t', header=None)\n",
    "with open(manifest_svs_path) as f:\n",
    "    manifest_files = f.readlines()\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "manifest_files = [x.strip() for x in manifest_files]\n",
    "print(f'number of files in manifest: {len(manifest_files)}')\n",
    "\n",
    "# get list of files in manifest that are in data dir\n",
    "manifest_files_in_data_dir = [f for f in manifest_files if f in svs_files]\n",
    "print(f'number of files in manifest that are in data dir: {len(manifest_files_in_data_dir)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the directories and files\n",
    "data_dir = 'tcga/brca'\n",
    "reference_file = '/home/neil/multimodal/data/stils_tcga_brca_ellogon.txt'\n",
    "manifest_path = '/home/neil/multimodal/data/stils_tcga_brca.txt'\n",
    "\n",
    "# Read the reference file into a set for faster lookup\n",
    "with open(reference_file, 'r') as f:\n",
    "    reference_set = set(line.strip() for line in f)\n",
    "\n",
    "# Initialize the list for the manifest\n",
    "manifest_list = []\n",
    "\n",
    "# Loop through all case folders in data_dir\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    # Filter for .svs files\n",
    "    svs_files = [file for file in files if file.endswith('.svs')]\n",
    "    if svs_files:\n",
    "        # Check if any of the .svs files are in the reference file\n",
    "        for svs_file in svs_files:\n",
    "            if svs_file in reference_set:\n",
    "                manifest_list.append(os.path.join(root, svs_file))\n",
    "                break\n",
    "        else:\n",
    "            # If no .svs file from the current folder is in the reference file, choose the first .svs file\n",
    "            manifest_list.append(os.path.join(root, svs_files[0]))\n",
    "\n",
    "# Save the list of files to the manifest path\n",
    "with open(manifest_path, 'w') as f:\n",
    "    for item in manifest_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy feature embs to/from case folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy feature embs from WSIs & reports to case folders\n",
    "# Directory where the feature embeddings are stored\n",
    "wsi_feats_dir = \"data/wsi_feats\"\n",
    "report_feats_dir = \"data/report_feats\"\n",
    "\n",
    "# Directory where the case folders are located\n",
    "dst_dir = \"/mnt/disks/ext/data/gdc/tcga/brca\"\n",
    "\n",
    "# Loop over all img feat files in the source directory\n",
    "for src_file in glob.glob(os.path.join(wsi_feats_dir, \"TCGA-*.pt\")):\n",
    "    # Extract the base name of the file\n",
    "    base_name = os.path.basename(src_file)\n",
    "\n",
    "    # Construct the destination directory path\n",
    "    dst_file = os.path.join(dst_dir, base_name[:12], base_name)\n",
    "\n",
    "    # Copy the file if it doesn't already exist\n",
    "    if not os.path.exists(dst_file):\n",
    "        shutil.copy(src_file, dst_file)\n",
    "    \n",
    "# Loop over all text feat files in the source directory\n",
    "for src_file in glob.glob(os.path.join(report_feats_dir, \"TCGA-*.pt\")):\n",
    "    # Extract the base name of the file\n",
    "    base_name = os.path.basename(src_file)\n",
    "\n",
    "    # Construct the destination directory path\n",
    "    dst_file = os.path.join(dst_dir, base_name[:12], base_name)\n",
    "\n",
    "    # Copy the file if it doesn't already exist\n",
    "    if not os.path.exists(dst_file):\n",
    "        shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy feature embs from WSIs & reports from case folders to separate folders\n",
    "# Directory where the case folders are located\n",
    "src_dir = \"/mnt/disks/ext/data/gdc/tcga/brca\"\n",
    "\n",
    "# Directory where the feature embeddings will be stored\n",
    "wsi_feats_dir = \"data/wsi_feats\"\n",
    "report_feats_dir = \"data/report_feats\"\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(wsi_feats_dir, exist_ok=True)\n",
    "os.makedirs(report_feats_dir, exist_ok=True)\n",
    "\n",
    "# Loop over all case folders in the source directory\n",
    "for case_folder in glob.glob(os.path.join(src_dir, \"TCGA-*\")):\n",
    "    # Loop over all img feat files in the case folder\n",
    "    for src_file in glob.glob(os.path.join(case_folder, \"*.wsi.pt\")):\n",
    "        # Extract the base name of the file\n",
    "        base_name = os.path.basename(src_file)\n",
    "\n",
    "        # Construct the destination file path\n",
    "        dst_file = os.path.join(wsi_feats_dir, base_name)\n",
    "\n",
    "        # Copy the file\n",
    "        shutil.copy(src_file, dst_file)\n",
    "\n",
    "    # Loop over all text feat files in the case folder\n",
    "    for src_file in glob.glob(os.path.join(case_folder, \"*.report.pt\")):\n",
    "        # Extract the base name of the file\n",
    "        base_name = os.path.basename(src_file)\n",
    "\n",
    "        # Construct the destination file path\n",
    "        dst_file = os.path.join(report_feats_dir, base_name)\n",
    "\n",
    "        # Copy the file\n",
    "        shutil.copy(src_file, dst_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create .csv file for loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotations\n",
    "annotations = pd.read_csv('data/stils/stils_tcga_ellogon.csv')\n",
    "\n",
    "# Set data dirs\n",
    "wsi_feats_dir = 'data/wsi_feats'\n",
    "report_feats_dir = 'data/report_feats'\n",
    "\n",
    "# Initialize the dataset\n",
    "df = []\n",
    "\n",
    "# Define the pattern for the case id\n",
    "case_pattern = r\"TCGA-\\w{2}-\\w{4}\"\n",
    "\n",
    "# Walk through the wsi_feats_dir\n",
    "for root, dirs, files in os.walk(wsi_feats_dir):\n",
    "    for file in files:\n",
    "        # Check if the file is a feature file\n",
    "        if file.endswith('.wsi.pt'):\n",
    "            # Extract the case id and slide id\n",
    "            case_id = file.split('.wsi.pt')[0][:12]\n",
    "            slide_id = file.split('.wsi.pt')[0]\n",
    "            \n",
    "            print(f'case_id: {case_id}, slide_id: {slide_id}')\n",
    "            \n",
    "            # Find the matching row in the annotations\n",
    "            annotation = annotations[annotations['Name'] == slide_id]\n",
    "            if not annotation.empty:\n",
    "                set = annotation['Set'].values[0]\n",
    "                sTIL_score = annotation['sTIL scores adjusted'].values[0]\n",
    "            else:\n",
    "                set = None\n",
    "                sTIL_score = None\n",
    "            \n",
    "            # Find the report file\n",
    "            report_feat_file = next((f for f in os.listdir(report_feats_dir) if f.startswith(case_id) and f.endswith('.report.pt')), None)\n",
    "            if report_feat_file is not None:\n",
    "                report_feat_path = os.path.join(report_feats_dir, report_feat_file)\n",
    "                # Add the data to the dataset\n",
    "                df.append([case_id, os.path.join(wsi_feats_dir, file), report_feat_path, set, sTIL_score])\n",
    "\n",
    "\n",
    "# Convert the dataset to a DataFrame and save it to a CSV file\n",
    "df = pd.DataFrame(df, columns=['case_id', 'wsi_feat_path', 'report_feat_path', 'set', 'sTIL_score'])\n",
    "\n",
    "# drop rows w/ no sTIL score\n",
    "df.dropna(subset=['sTIL_score'], inplace=True)\n",
    "\n",
    "# Replace 'Training' with 'train' and 'Test' with 'test' in the 'set' column\n",
    "df['set'] = df['set'].replace({'Training': 'train', 'Test': 'test', 'Validation': 'val'})\n",
    "\n",
    "# bucketize sTIL scores\n",
    "df['sTIL_level'] = df['sTIL_score'].apply(lambda x: int(x // 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cases w sTIL scores: 535 / 535\n",
      "number of cases w set labels: 534 / 535\n"
     ]
    }
   ],
   "source": [
    "# save dataset to csv\n",
    "# dataset_path = os.path.join(data_dir, 'dataset.csv')\n",
    "dataset_path = 'data/stils/dataset_stils.csv'\n",
    "df.to_csv(dataset_path, index=False)\n",
    "\n",
    "# dataset.head(20)\n",
    "# count # of cases w sTIL scores & set labels\n",
    "# dataset = pd.read_csv('tcga/brca/dataset.csv')\n",
    "print(f\"number of cases w sTIL scores: {df['sTIL_score'].count()} / {len(df)}\")\n",
    "print(f\"number of cases w set labels: {df['set'].count()} / {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
