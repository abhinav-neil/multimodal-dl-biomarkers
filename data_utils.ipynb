{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "import shutil\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pypdf import PdfReader\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restructure tcga data folders by case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# define the base directory\n",
    "base_dir = '/mnt/disks/ext/data/gdc/tcga/brca/'\n",
    "# Define the pattern for the case id\n",
    "pattern = r\"TCGA-\\w{2}-\\w{4}\"\n",
    "# Iterate over all directories in the base directory\n",
    "for dirpath, dirnames, filenames in os.walk(base_dir):\n",
    "    for filename in filenames:\n",
    "        # Find the case id in the filename\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            case_id = match.group()\n",
    "            # Create a new directory for this case id, if it doesn't exist\n",
    "            new_dir = os.path.join(base_dir, case_id)\n",
    "            os.makedirs(new_dir, exist_ok=True)\n",
    "            # Move the file to the new directory\n",
    "            shutil.move(os.path.join(dirpath, filename), os.path.join(new_dir, filename))\n",
    "\n",
    "# move other folders/files, except for the case folders, to misc folder\n",
    "# Define the pattern for the case id and the 8-digit alphanumeric\n",
    "case_pattern = r\"TCGA-\\w{2}-\\w{4}\"\n",
    "misc_pattern = r\"^[a-z0-9]{8}-\"\n",
    "\n",
    "# Create the 'misc' directory if it doesn't exist\n",
    "misc_dir = os.path.join(base_dir, 'misc')\n",
    "os.makedirs(misc_dir, exist_ok=True)\n",
    "\n",
    "# Create a list to store directories to be moved\n",
    "dirs_to_move = []\n",
    "\n",
    "# Generate a list of all directories in the base directory\n",
    "all_dirs = [x[0] for x in os.walk(base_dir) if not x[0].startswith(misc_dir)]\n",
    "\n",
    "# Iterate over all directories in the list\n",
    "for dirpath in all_dirs:\n",
    "    # If the directory is empty, remove it\n",
    "    if dirpath != base_dir and not any(os.scandir(dirpath)):\n",
    "        os.rmdir(dirpath)\n",
    "    else:\n",
    "        # If the directory name starts with an 8-digit alphanumeric followed by a hyphen\n",
    "        # and it's not a case directory, add it to the list of directories to be moved\n",
    "        dirname = os.path.basename(dirpath)\n",
    "        if re.match(misc_pattern, dirname) and not re.match(case_pattern, dirname):\n",
    "            dirs_to_move.append(dirpath)\n",
    "\n",
    "# Move the directories in the list to the 'misc' directory\n",
    "for dirpath in dirs_to_move:\n",
    "    if os.path.exists(dirpath):  # Check if the directory still exists\n",
    "        dest_dir = os.path.join(misc_dir, os.path.basename(dirpath))\n",
    "        if os.path.exists(dest_dir):\n",
    "            shutil.rmtree(dest_dir)\n",
    "        shutil.move(dirpath, dest_dir)\n",
    "# count # cases in base dir\n",
    "case_count = 0\n",
    "\n",
    "# Iterate over all directories in the base directory\n",
    "for dirpath, dirnames, _ in os.walk(base_dir):\n",
    "    # If the directory name matches the case id pattern, increment the counter\n",
    "    dirname = os.path.basename(dirpath)\n",
    "    if re.match(case_pattern, dirname):\n",
    "        case_count += 1\n",
    "\n",
    "print(f\"total number of case directories: {case_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pdf to text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Call the function\n",
    "extract_text_from_pdf('/mnt/disks/ext/data/gdc/tcga/brca/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create manifest file for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of wsis: 3110\n",
      "# annotations: 700\n",
      "# annotated wsis: 700\n",
      "# annotated cases: 688\n",
      "# annotated wsis in manifest: 688\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "# set data dir\n",
    "data_dir = '/mnt/disks/ext/data/gdc/tcga/brca/'\n",
    "# list all case folders in data dir (i.e. all folders that start with 'TCGA-')\n",
    "case_dirs = [f for f in os.listdir(data_dir) if isdir(join(data_dir, f)) and f.startswith('TCGA-')]\n",
    "# get list of all .svs files in each case folder\n",
    "all_wsis = []\n",
    "for case_dir in case_dirs:\n",
    "    all_wsis.extend([f for f in os.listdir(join(data_dir, case_dir)) if f.endswith('.svs')])\n",
    "print(f'total # of wsis: {len(all_wsis)}')\n",
    "# remove '.svs' from file names\n",
    "all_wsis = [f.replace('.svs', '') for f in all_wsis]\n",
    " \n",
    "stils_tcga_elg_path = 'data/stils/stils_tcga_ellogon.tsv'\n",
    "wsis_stils_elg = pd.read_csv(stils_tcga_elg_path, sep='\\t')['wsi_id'].tolist()\n",
    "print(f'# annotations: {len(wsis_stils_elg)}')\n",
    "\n",
    "# get list of files in manifest that are in data dir\n",
    "annotated_wsis = [f for f in wsis_stils_elg if f in all_wsis]\n",
    "print(f'# annotated wsis: {len(annotated_wsis)}')\n",
    "\n",
    "# Initialize the directories and files\n",
    "data_dir = '/mnt/disks/ext/data/gdc/tcga/brca'\n",
    "# reference_file = '/home/neil/multimodal/data/stils_tcga_brca_annotated.txt'\n",
    "wsi_stils_feats_manifest_path = 'data/stils/wsi_stils_feats_manifest.txt'\n",
    "\n",
    "# Initialize the list for the manifest\n",
    "wsi_stils_annot_paths = []\n",
    "\n",
    "# Loop through all case folders in data_dir\n",
    "case_ids_annot = []\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    # Filter for .svs files\n",
    "    all_wsi_paths = [file for file in files if file.endswith('.svs')]\n",
    "    if all_wsi_paths:\n",
    "        # Check if any of the .svs files are in the reference file\n",
    "        for wsi_path in all_wsi_paths:\n",
    "            if wsi_path.replace('.svs', '') in annotated_wsis:\n",
    "                wsi_stils_annot_paths.append(os.path.join(os.path.basename(root), wsi_path))\n",
    "                case_ids_annot.append(os.path.basename(root))\n",
    "                break\n",
    "print(f'# annotated cases: {len(set(case_ids_annot))}')\n",
    "\n",
    "# Save the list of files to the manifest path\n",
    "print(f'# annotated wsis in manifest: {len(wsi_stils_annot_paths)}')\n",
    "# with open(wsi_stils_feats_manifest_path, 'w') as f:\n",
    "#     for item in wsi_stils_annot_paths:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy feature embs to/from case folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Copy feature embs from WSIs & reports to case folders\n",
    "# Directory where the feature embeddings are stored\n",
    "wsi_feats_dir = \"data/wsi_feats\"\n",
    "report_feats_dir = \"data/report_feats\"\n",
    "\n",
    "# Directory where the case folders are located\n",
    "dst_dir = \"/mnt/disks/ext/data/gdc/tcga/brca\"\n",
    "\n",
    "# Loop over all img feat files in the source directory\n",
    "for src_file in glob.glob(os.path.join(wsi_feats_dir, \"TCGA-*.pt\")):\n",
    "    # Extract the base name of the file\n",
    "    base_name = os.path.basename(src_file)\n",
    "\n",
    "    # Construct the destination directory path\n",
    "    dst_file = os.path.join(dst_dir, base_name[:12], base_name)\n",
    "\n",
    "    # Copy the file if it doesn't already exist\n",
    "    if not os.path.exists(dst_file):\n",
    "        shutil.copy(src_file, dst_file)\n",
    "    \n",
    "# Loop over all text feat files in the source directory\n",
    "for src_file in glob.glob(os.path.join(report_feats_dir, \"TCGA-*.pt\")):\n",
    "    # Extract the base name of the file\n",
    "    base_name = os.path.basename(src_file)\n",
    "\n",
    "    # Construct the destination directory path\n",
    "    dst_file = os.path.join(dst_dir, base_name[:12], base_name)\n",
    "\n",
    "    # Copy the file if it doesn't already exist\n",
    "    if not os.path.exists(dst_file):\n",
    "        shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Copy feature embs from WSIs & reports from case folders to separate folders\n",
    "# Directory where the case folders are located\n",
    "src_dir = \"/mnt/disks/ext/data/gdc/tcga/brca\"\n",
    "\n",
    "# Directory where the feature embeddings will be stored\n",
    "wsi_feats_dir = \"data/wsi_feats\"\n",
    "report_feats_dir = \"data/report_feats\"\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(wsi_feats_dir, exist_ok=True)\n",
    "os.makedirs(report_feats_dir, exist_ok=True)\n",
    "\n",
    "# Loop over all case folders in the source directory\n",
    "for case_folder in glob.glob(os.path.join(src_dir, \"TCGA-*\")):\n",
    "    # Loop over all img feat files in the case folder\n",
    "    for src_file in glob.glob(os.path.join(case_folder, \"*.wsi.pt\")):\n",
    "        # Extract the base name of the file\n",
    "        base_name = os.path.basename(src_file)\n",
    "\n",
    "        # Construct the destination file path\n",
    "        dst_file = os.path.join(wsi_feats_dir, base_name)\n",
    "\n",
    "        # Copy the file\n",
    "        shutil.copy(src_file, dst_file)\n",
    "\n",
    "    # Loop over all text feat files in the case folder\n",
    "    for src_file in glob.glob(os.path.join(case_folder, \"*.report.pt\")):\n",
    "        # Extract the base name of the file\n",
    "        base_name = os.path.basename(src_file)\n",
    "\n",
    "        # Construct the destination file path\n",
    "        dst_file = os.path.join(report_feats_dir, base_name)\n",
    "\n",
    "        # Copy the file\n",
    "        shutil.copy(src_file, dst_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create .csv file for loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotations\n",
    "wsi_stils_annot = pd.read_csv('data/stils/stils_tcga_ellogon.tsv', sep='\\t')\n",
    "\n",
    "# Set data dirs\n",
    "wsi_feats_dir = 'data/wsi_feats'\n",
    "report_feats_dir = 'data/report_feats'\n",
    "\n",
    "# Initialize the dataset\n",
    "df = []\n",
    "\n",
    "# Define the pattern for the case id\n",
    "case_pattern = r\"TCGA-\\w{2}-\\w{4}\"\n",
    "\n",
    "# Walk through the wsi_feats_dir\n",
    "for root, dirs, files in os.walk(wsi_feats_dir):\n",
    "    for wsi_feat_file in files:\n",
    "        # Check if the file is a feature file\n",
    "        if wsi_feat_file.endswith('.wsi.pt'):\n",
    "            # Extract the case id and slide id\n",
    "            case_id = wsi_feat_file.split('.wsi.pt')[0][:12]\n",
    "            slide_id = wsi_feat_file.split('.wsi.pt')[0]\n",
    "            \n",
    "            # print(f'case_id: {case_id}, slide_id: {slide_id}')\n",
    "            \n",
    "            # Find the matching row in the annotations\n",
    "            annot = wsi_stils_annot[wsi_stils_annot['wsi_id'] == slide_id]\n",
    "            split, stil_score = annot['split'].values[0], annot['stil_score'].values[0] if not annot.empty else (None, None)\n",
    "            \n",
    "            # Find the report file\n",
    "            report_feat_file = next((f for f in os.listdir(report_feats_dir) if f.startswith(case_id) and f.endswith('.report.pt')), None)\n",
    "            if report_feat_file is not None:\n",
    "                report_feat_path = os.path.join(report_feats_dir, report_feat_file)\n",
    "                wsi_feat_path = os.path.join(wsi_feats_dir, wsi_feat_file)\n",
    "                # Add the data to the dataset\n",
    "                df.append([case_id, wsi_feat_path, report_feat_path, split, stil_score])\n",
    "\n",
    "\n",
    "# Convert the dataset to a DataFrame and save it to a CSV file\n",
    "df = pd.DataFrame(df, columns=['case_id', 'wsi_feat_path', 'report_feat_path', 'split', 'stil_score'])\n",
    "\n",
    "# drop rows w/ no sTIL score\n",
    "df.dropna(subset=['stil_score'], inplace=True)\n",
    "\n",
    "# Replace 'Training' with 'train' and 'Test' with 'test' in the 'set' column\n",
    "# df['set'] = df['set'].replace({'Training': 'train', 'Test': 'test', 'Validation': 'val'})\n",
    "\n",
    "# bucketize sTIL scores\n",
    "df['stil_lvl'] = df['stil_score'].apply(lambda x: int(x // 0.1))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cases w sTIL scores: 684 / 684\n",
      "number of cases w split labels: 684 / 684\n"
     ]
    }
   ],
   "source": [
    "# save dataset to csv\n",
    "# dataset_path = os.path.join(data_dir, 'dataset.csv')\n",
    "data_path = 'data/stils/data_stils.csv'\n",
    "df.to_csv(data_path, index=False)\n",
    "\n",
    "# dataset.head(20)\n",
    "# count # of cases w sTIL scores & set labels\n",
    "# dataset = pd.read_csv('tcga/brca/dataset.csv')\n",
    "print(f\"number of cases w sTIL scores: {df['stil_score'].count()} / {len(df)}\")\n",
    "print(f\"number of cases w split labels: {df['split'].count()} / {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
