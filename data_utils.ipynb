{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "import shutil\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pypdf import PdfReader\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restructure tcga data folders by case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# define the base directory\n",
    "base_dir = '/mnt/disks/ext/data/gdc/tcga/brca/'\n",
    "# Define the pattern for the case id\n",
    "pattern = r\"TCGA-\\w{2}-\\w{4}\"\n",
    "# Iterate over all directories in the base directory\n",
    "for dirpath, dirnames, filenames in os.walk(base_dir):\n",
    "    for filename in filenames:\n",
    "        # Find the case id in the filename\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            case_id = match.group()\n",
    "            # Create a new directory for this case id, if it doesn't exist\n",
    "            new_dir = os.path.join(base_dir, case_id)\n",
    "            os.makedirs(new_dir, exist_ok=True)\n",
    "            # Move the file to the new directory\n",
    "            shutil.move(os.path.join(dirpath, filename), os.path.join(new_dir, filename))\n",
    "\n",
    "# move other folders/files, except for the case folders, to misc folder\n",
    "# Define the pattern for the case id and the 8-digit alphanumeric\n",
    "case_pattern = r\"TCGA-\\w{2}-\\w{4}\"\n",
    "misc_pattern = r\"^[a-z0-9]{8}-\"\n",
    "\n",
    "# Create the 'misc' directory if it doesn't exist\n",
    "misc_dir = os.path.join(base_dir, 'misc')\n",
    "os.makedirs(misc_dir, exist_ok=True)\n",
    "\n",
    "# Create a list to store directories to be moved\n",
    "dirs_to_move = []\n",
    "\n",
    "# Generate a list of all directories in the base directory\n",
    "all_dirs = [x[0] for x in os.walk(base_dir) if not x[0].startswith(misc_dir)]\n",
    "\n",
    "# Iterate over all directories in the list\n",
    "for dirpath in all_dirs:\n",
    "    # If the directory is empty, remove it\n",
    "    if dirpath != base_dir and not any(os.scandir(dirpath)):\n",
    "        os.rmdir(dirpath)\n",
    "    else:\n",
    "        # If the directory name starts with an 8-digit alphanumeric followed by a hyphen\n",
    "        # and it's not a case directory, add it to the list of directories to be moved\n",
    "        dirname = os.path.basename(dirpath)\n",
    "        if re.match(misc_pattern, dirname) and not re.match(case_pattern, dirname):\n",
    "            dirs_to_move.append(dirpath)\n",
    "\n",
    "# Move the directories in the list to the 'misc' directory\n",
    "for dirpath in dirs_to_move:\n",
    "    if os.path.exists(dirpath):  # Check if the directory still exists\n",
    "        dest_dir = os.path.join(misc_dir, os.path.basename(dirpath))\n",
    "        if os.path.exists(dest_dir):\n",
    "            shutil.rmtree(dest_dir)\n",
    "        shutil.move(dirpath, dest_dir)\n",
    "# count # cases in base dir\n",
    "case_count = 0\n",
    "\n",
    "# Iterate over all directories in the base directory\n",
    "for dirpath, dirnames, _ in os.walk(base_dir):\n",
    "    # If the directory name matches the case id pattern, increment the counter\n",
    "    dirname = os.path.basename(dirpath)\n",
    "    if re.match(case_pattern, dirname):\n",
    "        case_count += 1\n",
    "\n",
    "print(f\"total number of case directories: {case_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pdf to text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Call the function\n",
    "extract_text_from_pdf('/mnt/disks/ext/data/gdc/tcga/brca/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create manifest file for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of wsis: 3110\n",
      "# annotations: 700\n",
      "# annotated wsis: 700\n",
      "# annotated wsis in manifest: 700\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "# set data dir\n",
    "data_dir = '/mnt/disks/ext/data/gdc/tcga/brca/'\n",
    "# list all case folders in data dir (i.e. all folders that start with 'TCGA-')\n",
    "case_dirs = [f for f in os.listdir(data_dir) if isdir(join(data_dir, f)) and f.startswith('TCGA-')]\n",
    "# get list of all .svs files in each case folder\n",
    "all_wsis = []\n",
    "for case_dir in case_dirs:\n",
    "    all_wsis.extend([f for f in os.listdir(join(data_dir, case_dir)) if f.endswith('.svs')])\n",
    "print(f'total # of wsis: {len(all_wsis)}')\n",
    "# remove '.svs' from file names\n",
    "all_wsis = [f.replace('.svs', '') for f in all_wsis]\n",
    " \n",
    "stils_tcga_elg_path = 'data/stils/stils_tcga_ellogon.tsv'\n",
    "wsis_stils_elg = pd.read_csv(stils_tcga_elg_path, sep='\\t')['wsi_id'].tolist()\n",
    "print(f'# annotations: {len(wsis_stils_elg)}')\n",
    "\n",
    "# get list of files in manifest that are in data dir\n",
    "annotated_wsis = [f for f in wsis_stils_elg if f in all_wsis]\n",
    "print(f'# annotated wsis: {len(annotated_wsis)}')\n",
    "\n",
    "# reference_file = '/home/neil/multimodal/data/stils_tcga_brca_annotated.txt'\n",
    "wsi_stils_feats_manifest_path = 'data/stils/wsi_stils_feats_manifest.txt'\n",
    "\n",
    "# Initialize the list for the manifest\n",
    "wsi_stils_annot_paths = []\n",
    "\n",
    "# Loop through all case folders in data_dir\n",
    "# case_ids_annot = []\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    # Filter for .svs files\n",
    "    all_wsi_paths = [file for file in files if file.endswith('.svs')]\n",
    "    if all_wsi_paths:\n",
    "        # Check if any of the .svs files are in the reference file\n",
    "        for wsi_path in all_wsi_paths:\n",
    "            if wsi_path.replace('.svs', '') in annotated_wsis:\n",
    "                wsi_stils_annot_paths.append(os.path.join(os.path.basename(root), wsi_path))\n",
    "                # case_ids_annot.append(os.path.basename(root))\n",
    "                # break\n",
    "# print(f'# annotated cases: {len(set(case_ids_annot))}')\n",
    "\n",
    "# Save the list of files to the manifest path\n",
    "print(f'# annotated wsis in manifest: {len(wsi_stils_annot_paths)}')\n",
    "with open(wsi_stils_feats_manifest_path, 'w') as f:\n",
    "    for item in wsi_stils_annot_paths:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy feature embs to/from case folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Copy feature embs from WSIs & reports to case folders\n",
    "# Directory where the feature embeddings are stored\n",
    "wsi_feats_dir = \"data/wsi_feats\"\n",
    "report_feats_dir = \"data/report_feats\"\n",
    "\n",
    "# Directory where the case folders are located\n",
    "dst_dir = \"/mnt/disks/ext/data/gdc/tcga/brca\"\n",
    "\n",
    "# Loop over all img feat files in the source directory\n",
    "for src_file in glob.glob(os.path.join(wsi_feats_dir, \"TCGA-*.pt\")):\n",
    "    # Extract the base name of the file\n",
    "    base_name = os.path.basename(src_file)\n",
    "\n",
    "    # Construct the destination directory path\n",
    "    dst_file = os.path.join(dst_dir, base_name[:12], base_name)\n",
    "\n",
    "    # Copy the file if it doesn't already exist\n",
    "    if not os.path.exists(dst_file):\n",
    "        shutil.copy(src_file, dst_file)\n",
    "    \n",
    "# Loop over all text feat files in the source directory\n",
    "for src_file in glob.glob(os.path.join(report_feats_dir, \"TCGA-*.pt\")):\n",
    "    # Extract the base name of the file\n",
    "    base_name = os.path.basename(src_file)\n",
    "\n",
    "    # Construct the destination directory path\n",
    "    dst_file = os.path.join(dst_dir, base_name[:12], base_name)\n",
    "\n",
    "    # Copy the file if it doesn't already exist\n",
    "    if not os.path.exists(dst_file):\n",
    "        shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Copy feature embs from WSIs & reports from case folders to separate folders\n",
    "# Directory where the case folders are located\n",
    "src_dir = \"/mnt/disks/ext/data/gdc/tcga/brca\"\n",
    "\n",
    "# Directory where the feature embeddings will be stored\n",
    "wsi_feats_dir = \"data/wsi_feats\"\n",
    "report_feats_dir = \"data/report_feats\"\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(wsi_feats_dir, exist_ok=True)\n",
    "os.makedirs(report_feats_dir, exist_ok=True)\n",
    "\n",
    "# Loop over all case folders in the source directory\n",
    "for case_folder in glob.glob(os.path.join(src_dir, \"TCGA-*\")):\n",
    "    # Loop over all img feat files in the case folder\n",
    "    for src_file in glob.glob(os.path.join(case_folder, \"*.wsi.pt\")):\n",
    "        # Extract the base name of the file\n",
    "        base_name = os.path.basename(src_file)\n",
    "\n",
    "        # Construct the destination file path\n",
    "        dst_file = os.path.join(wsi_feats_dir, base_name)\n",
    "\n",
    "        # Copy the file\n",
    "        shutil.copy(src_file, dst_file)\n",
    "\n",
    "    # Loop over all text feat files in the case folder\n",
    "    for src_file in glob.glob(os.path.join(case_folder, \"*.report.pt\")):\n",
    "        # Extract the base name of the file\n",
    "        base_name = os.path.basename(src_file)\n",
    "\n",
    "        # Construct the destination file path\n",
    "        dst_file = os.path.join(report_feats_dir, base_name)\n",
    "\n",
    "        # Copy the file\n",
    "        shutil.copy(src_file, dst_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create .csv file for loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 696\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>wsi_feat_path</th>\n",
       "      <th>report_feat_path</th>\n",
       "      <th>split</th>\n",
       "      <th>stil_score</th>\n",
       "      <th>stil_lvl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-AR-A1AX</td>\n",
       "      <td>data/wsi_feats/TCGA-AR-A1AX-01Z-00-DX1.2389D54F-545E-499E-B392-DD731834460A.wsi.pt</td>\n",
       "      <td>data/report_feats/TCGA-AR-A1AX.4FDBA110-6E14-428C-BF82-168AE28A14E4.report.pt</td>\n",
       "      <td>test</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-AN-A0XL</td>\n",
       "      <td>data/wsi_feats/TCGA-AN-A0XL-01Z-00-DX1.E90AA056-51DC-4A6B-96EB-A0B707496912.wsi.pt</td>\n",
       "      <td>data/report_feats/TCGA-AN-A0XL.A85A959B-F18C-43D3-8BBF-770DA2189462.report.pt</td>\n",
       "      <td>test</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-C8-A1HN</td>\n",
       "      <td>data/wsi_feats/TCGA-C8-A1HN-01Z-00-DX1.7EBBEAB1-EBB7-456F-8848-AFE2263242B7.wsi.pt</td>\n",
       "      <td>data/report_feats/TCGA-C8-A1HN.4C7445ED-B346-4DD7-8AFA-2E95E65364BF.report.pt</td>\n",
       "      <td>test</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-AN-A0AT</td>\n",
       "      <td>data/wsi_feats/TCGA-AN-A0AT-01Z-00-DX1.DFD68CD2-C25E-47BE-BC06-8CE3C657B9FD.wsi.pt</td>\n",
       "      <td>data/report_feats/TCGA-AN-A0AT.3E8F2012-A457-4358-9C8B-23292374A743.report.pt</td>\n",
       "      <td>train</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-E9-A1R7</td>\n",
       "      <td>data/wsi_feats/TCGA-E9-A1R7-01Z-00-DX1.af9ff432-440e-44ac-bc33-298f5db9a706.wsi.pt</td>\n",
       "      <td>data/report_feats/TCGA-E9-A1R7.FA19C3C4-E13B-464B-84CC-3AF7E83D5B9C.report.pt</td>\n",
       "      <td>train</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        case_id  \\\n",
       "0  TCGA-AR-A1AX   \n",
       "1  TCGA-AN-A0XL   \n",
       "2  TCGA-C8-A1HN   \n",
       "3  TCGA-AN-A0AT   \n",
       "4  TCGA-E9-A1R7   \n",
       "\n",
       "                                                                        wsi_feat_path  \\\n",
       "0  data/wsi_feats/TCGA-AR-A1AX-01Z-00-DX1.2389D54F-545E-499E-B392-DD731834460A.wsi.pt   \n",
       "1  data/wsi_feats/TCGA-AN-A0XL-01Z-00-DX1.E90AA056-51DC-4A6B-96EB-A0B707496912.wsi.pt   \n",
       "2  data/wsi_feats/TCGA-C8-A1HN-01Z-00-DX1.7EBBEAB1-EBB7-456F-8848-AFE2263242B7.wsi.pt   \n",
       "3  data/wsi_feats/TCGA-AN-A0AT-01Z-00-DX1.DFD68CD2-C25E-47BE-BC06-8CE3C657B9FD.wsi.pt   \n",
       "4  data/wsi_feats/TCGA-E9-A1R7-01Z-00-DX1.af9ff432-440e-44ac-bc33-298f5db9a706.wsi.pt   \n",
       "\n",
       "                                                                report_feat_path  \\\n",
       "0  data/report_feats/TCGA-AR-A1AX.4FDBA110-6E14-428C-BF82-168AE28A14E4.report.pt   \n",
       "1  data/report_feats/TCGA-AN-A0XL.A85A959B-F18C-43D3-8BBF-770DA2189462.report.pt   \n",
       "2  data/report_feats/TCGA-C8-A1HN.4C7445ED-B346-4DD7-8AFA-2E95E65364BF.report.pt   \n",
       "3  data/report_feats/TCGA-AN-A0AT.3E8F2012-A457-4358-9C8B-23292374A743.report.pt   \n",
       "4  data/report_feats/TCGA-E9-A1R7.FA19C3C4-E13B-464B-84CC-3AF7E83D5B9C.report.pt   \n",
       "\n",
       "   split  stil_score  stil_lvl  \n",
       "0   test        0.30         2  \n",
       "1   test        0.06         0  \n",
       "2   test        0.38         3  \n",
       "3  train        0.55         5  \n",
       "4  train        0.03         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the annotations\n",
    "wsi_stils_annot = pd.read_csv('data/stils/stils_tcga_ellogon.tsv', sep='\\t')\n",
    "\n",
    "# Set data dirs\n",
    "wsi_feats_dir = 'data/wsi_feats'\n",
    "report_feats_dir = 'data/report_feats'\n",
    "\n",
    "# Initialize the dataset\n",
    "df = []\n",
    "\n",
    "# Define the pattern for the case id\n",
    "case_pattern = r\"TCGA-\\w{2}-\\w{4}\"\n",
    "\n",
    "# Walk through the wsi_feats_dir\n",
    "for root, dirs, files in os.walk(wsi_feats_dir):\n",
    "    for wsi_feat_file in files:\n",
    "        # Check if the file is a feature file\n",
    "        if wsi_feat_file.endswith('.wsi.pt'):\n",
    "            # Extract the case id and slide id\n",
    "            case_id = wsi_feat_file.split('.wsi.pt')[0][:12]\n",
    "            slide_id = wsi_feat_file.split('.wsi.pt')[0]\n",
    "            \n",
    "            # print(f'case_id: {case_id}, slide_id: {slide_id}')\n",
    "            \n",
    "            # Find the matching row in the annotations\n",
    "            annot = wsi_stils_annot[wsi_stils_annot['wsi_id'] == slide_id]\n",
    "            split, stil_score = annot['split'].values[0], annot['stil_score'].values[0] if not annot.empty else (None, None)\n",
    "            \n",
    "            # Find the report file\n",
    "            report_feat_file = next((f for f in os.listdir(report_feats_dir) if f.startswith(case_id) and f.endswith('.report.pt')), None)\n",
    "            if report_feat_file is not None:\n",
    "                report_feat_path = os.path.join(report_feats_dir, report_feat_file)\n",
    "                wsi_feat_path = os.path.join(wsi_feats_dir, wsi_feat_file)\n",
    "                # Add the data to the dataset\n",
    "                df.append([case_id, wsi_feat_path, report_feat_path, split, stil_score])\n",
    "\n",
    "\n",
    "# Convert the dataset to a DataFrame and save it to a CSV file\n",
    "df = pd.DataFrame(df, columns=['case_id', 'wsi_feat_path', 'report_feat_path', 'split', 'stil_score'])\n",
    "\n",
    "# drop rows w/ no sTIL score\n",
    "df.dropna(subset=['stil_score'], inplace=True)\n",
    "\n",
    "# df['set'] = df['set'].replace({'Training': 'train', 'Test': 'test', 'Validation': 'val'})\n",
    "\n",
    "# bucketize sTIL scores\n",
    "df['stil_lvl'] = df['stil_score'].apply(lambda x: int(x // 0.1))\n",
    "\n",
    "print(f'# samples: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cases w sTIL scores: 696 / 696\n",
      "number of cases w split labels: 696 / 696\n"
     ]
    }
   ],
   "source": [
    "# save dataset to csv\n",
    "# dataset_path = os.path.join(data_dir, 'dataset.csv')\n",
    "data_path = 'data/stils/data_stils.csv'\n",
    "df.to_csv(data_path, index=False)\n",
    "\n",
    "# dataset.head(20)\n",
    "# count # of cases w sTIL scores & set labels\n",
    "# dataset = pd.read_csv('tcga/brca/dataset.csv')\n",
    "print(f\"number of cases w sTIL scores: {df['stil_score'].count()} / {len(df)}\")\n",
    "print(f\"number of cases w split labels: {df['split'].count()} / {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename report files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_dir = 'data/reports_processed'\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(reports_dir):\n",
    "    # Check if the filename matches the pattern 'TCGA-XX-XXXX.*.txt'\n",
    "    if filename.startswith('TCGA-') and filename.endswith('.txt'):\n",
    "        # Extract the case_id (first 12 characters)\n",
    "        case_id = filename[:12]\n",
    "        new_filename = f\"{case_id}.txt\"\n",
    "        \n",
    "        # Construct the full paths for the source and destination\n",
    "        src_path = os.path.join(reports_dir, filename)\n",
    "        dest_path = os.path.join(reports_dir, new_filename)\n",
    "        \n",
    "        # Check if the destination filename already exists\n",
    "        if os.path.exists(dest_path):\n",
    "            print(f\"destination filename {dest_path} already exists!\")\n",
    "        else:\n",
    "            # Rename the file\n",
    "            os.rename(src_path, dest_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract relevant info (summarize) from reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_reports(reports_dir, summary_dir, rest_dir):\n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(summary_dir, exist_ok=True)\n",
    "    os.makedirs(rest_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through all the reports in the reports_dir\n",
    "    for report_file in os.listdir(reports_dir):\n",
    "        if report_file.endswith('.txt'):\n",
    "            with open(os.path.join(reports_dir, report_file), 'r') as f:\n",
    "                report = f.read()\n",
    "\n",
    "                # Extract relevant sentences for subtype and grade\n",
    "                keywords = ['carcinoma', 'grade']\n",
    "                # This regex will match any sentence containing any of the keywords\n",
    "                pattern = r'([^.!?\\n]*\\b(?:' + '|'.join(keywords) + r')\\b[^.!?]*[.!?\\n])'\n",
    "                rel_sents = re.findall(pattern, report, re.IGNORECASE)\n",
    "\n",
    "                # Combine the extracted sentences\n",
    "                summary = ' '.join(rel_sents)\n",
    "\n",
    "                # Get the rest of the report (minus the relevant sentences)\n",
    "                rest = report.replace(summary, '')\n",
    "\n",
    "                # Save the summary and rest to their respective directories\n",
    "                with open(os.path.join(summary_dir, report_file), 'w') as f_summary:\n",
    "                    f_summary.write(summary)\n",
    "                with open(os.path.join(rest_dir, report_file), 'w') as f_rest:\n",
    "                    f_rest.write(rest)\n",
    "\n",
    "# Define your directories\n",
    "reports_dir = 'data/reports'\n",
    "summary_dir = 'data/reports_distilled'\n",
    "rest_dir = 'data/reports_residual'\n",
    "\n",
    "# Extract and save the reports\n",
    "extract_and_save_reports(reports_dir, summary_dir, rest_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
