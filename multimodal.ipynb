{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.utils import *\n",
    "from src.models import MLPSTILClassifier, Attention1DSTILClassifier, Attention2DSTILClassifier, MLPSTILRegressor, Attention1DSTILRegressor, Attention2DSTILRegressor\n",
    "from src.train import train_mm_stil, kfold_cv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seed & device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)      \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text feats from reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# load biobert model & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(''dmis-lab/biobert-large-cased-v1.1-mnli)\n",
    "lm = AutoModel.from_pretrained('dmis-lab/biobert-large-cased-v1.1-mnli')\n",
    "data_dir = '/mnt/disks/ext/data/gdc/tcga/brca'\n",
    "output_dir = 'data/report_feats'\n",
    "extract_text_features(lm, tokenizer, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Predict sTILs from WSIs & reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 16 # batch size for dataloaders\n",
    "img_channels_in = 2048  # emb dim of wsi feats\n",
    "text_channels_in = 1024 # emb dim of report feats\n",
    "hidden_dim_mlp = 16 # hidden layer dim of mlp\n",
    "num_classes = 10 # number of stil levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train set: 468, val set: 58, test set: 170\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "root_dir = './'\n",
    "data_file = 'data/stils/data_stils.csv'\n",
    "use_rand_splits = False # use random splits or predefined splits\n",
    "train_data = MMDataset(root_dir, data_file, 'train', use_rand_splits)\n",
    "val_data = MMDataset(root_dir, data_file, 'val', use_rand_splits)\n",
    "test_data = MMDataset(root_dir, data_file, 'test', use_rand_splits)\n",
    "\n",
    "print(f'size of train set: {len(train_data)}, val set: {len(val_data)}, test set: {len(test_data)}')\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=bsz, shuffle=True, num_workers=12, collate_fn=MMDataset.mm_collate_fn)\n",
    "val_loader = DataLoader(val_data, batch_size=bsz, shuffle=False, num_workers=12, collate_fn=MMDataset.mm_collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=bsz, shuffle=False, num_workers=12, collate_fn=MMDataset.mm_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# init model (one of: MLPSTILClassifier, MLPSTILRegressor, Attention1DSTILClassifier, Attention1DSTILRegressor, Attention2DSTILClassifier, Attention2DSTILRegressor) \n",
    "model = Attention1DSTILRegressor(mode='image')\n",
    "\n",
    "# set training args\n",
    "num_epochs = 50\n",
    "resume_ckpt = None\n",
    "args = {'num_epochs': num_epochs, 'ckpt_name': 'ckpt_best_img'}\n",
    "\n",
    "# train model\n",
    "model, trainer = train_mm_stil(model, train_loader, val_loader, args)\n",
    "\n",
    "# evaluate the trained model on the test set\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# run k-fold CV\n",
    "dataset = MMDataset()\n",
    "\n",
    "model_class = Attention1DSTILRegressor\n",
    "model_args = {'mode': 'image'}\n",
    "train_args = {'k': 5, 'num_epochs': 50, 'ckpt_name': 'ckpt_best_img_kfold_cv'}\n",
    "\n",
    "res_kfold_cv = kfold_cv(model_class, dataset, model_args, train_args)\n",
    "metrics = ['test_loss', 'test_corr', 'test_r2']\n",
    "avg_res = {k: np.mean([res[k] for res in res_kfold_cv]).round(3) for k in metrics}\n",
    "print(f\"avg res over {train_args['k']} folds: {avg_res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Predict cancer subtypes from multimodal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cancer subtype annotations from path reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Region: lobular\n",
      "Predicted Degree of Localization: in-situ\n"
     ]
    }
   ],
   "source": [
    "# load pretrainer BioBERT model\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# load biobert model & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-large-cased-v1.1-mnli')\n",
    "lm = AutoModelForSequenceClassification.from_pretrained('dmis-lab/biobert-large-cased-v1.1-mnli')\n",
    "\n",
    "# Define the possible cancer subtypes\n",
    "# Define the labels for each category\n",
    "region_labels = ['ductal', 'lobular', 'metastatic']\n",
    "localization_labels = ['in-situ', 'invasive', 'metastatic']\n",
    "\n",
    "# Create a zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=lm, tokenizer=tokenizer)\n",
    "\n",
    "# For demonstration, let's classify a single report\n",
    "sample_report_path = 'data/reports_processed/TCGA-3C-AALJ.265E5A9A-64FD-4B86-89BC-5E89F253C118.txt'\n",
    "with open(sample_report_path, 'r') as f:\n",
    "    sample_report = f.read()\n",
    "    \n",
    "# Use the classifier\n",
    "# results = classifier(sample_report, labels)\n",
    "# Tokenize the report and split it into overlapping chunks\n",
    "max_length = 512 - 2  # account for [CLS] and [SEP] tokens\n",
    "overlap = 100\n",
    "tokens = tokenizer.tokenize(sample_report)\n",
    "# Create overlapping chunks\n",
    "chunk_size = max_length - overlap - 2  # account for [CLS] and [SEP] tokens and overlap\n",
    "chunks = [tokens[i:i+chunk_size] for i in range(0, len(tokens), chunk_size - overlap)]\n",
    "\n",
    "# Initialize scores for each label\n",
    "region_scores = {label: 0 for label in region_labels}\n",
    "localization_scores = {label: 0 for label in localization_labels}\n",
    "\n",
    "# Classify each chunk and aggregate the results\n",
    "for chunk in chunks:\n",
    "    chunk_text = tokenizer.decode(tokenizer.convert_tokens_to_ids(chunk))\n",
    "    \n",
    "    # Classify for region\n",
    "    region_result = classifier(chunk_text, region_labels)\n",
    "    for label, score in zip(region_result[\"labels\"], region_result[\"scores\"]):\n",
    "        region_scores[label] += score\n",
    "        \n",
    "    # Classify for localization\n",
    "    localization_result = classifier(chunk_text, localization_labels)\n",
    "    for label, score in zip(localization_result[\"labels\"], localization_result[\"scores\"]):\n",
    "        localization_scores[label] += score\n",
    "\n",
    "# The predicted subtype will be the label with the highest score\n",
    "# predicted_subtype = results[\"labels\"][0]  # The labels are ordered from highest to lowest score\n",
    "# The predicted subtype will be the label with the highest aggregated score\n",
    "# The predicted subtype for each category will be the label with the highest aggregated score\n",
    "predicted_region = max(region_scores, key=region_scores.get)\n",
    "predicted_localization = max(localization_scores, key=localization_scores.get)\n",
    "\n",
    "print(\"Predicted Region:\", predicted_region)\n",
    "print(\"Predicted Degree of Localization:\", predicted_localization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
