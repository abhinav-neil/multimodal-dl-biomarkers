{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.utils import *\n",
    "from src.models import MLPSTILClassifier, Attention1DSTILClassifier, Attention2DSTILClassifier, MLPSTILRegressor, Attention1DSTILRegressor, Attention2DSTILRegressor\n",
    "from src.train import train_mm_stil, kfold_cv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seed & device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)      \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text feats from reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# load biobert model & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-large-cased-v1.1-mnli')\n",
    "lm = AutoModel.from_pretrained('dmis-lab/biobert-large-cased-v1.1-mnli')\n",
    "data_dir = '/mnt/disks/ext/data/gdc/tcga/brca'\n",
    "output_dir = 'data/report_feats'\n",
    "extract_text_features(lm, tokenizer, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Predict sTILs from WSIs & reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 16 # batch size for dataloaders\n",
    "img_channels_in = 2048  # emb dim of wsi feats\n",
    "text_channels_in = 1024 # emb dim of report feats\n",
    "hidden_dim_mlp = 16 # hidden layer dim of mlp\n",
    "num_classes = 10 # number of stil levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train set: 468, val set: 58, test set: 170\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "root_dir = './'\n",
    "data_file = 'data/stils/data_stils.csv'\n",
    "use_rand_splits = False # use random splits or predefined splits\n",
    "train_data = MMDataset(root_dir, data_file, 'train', use_rand_splits)\n",
    "val_data = MMDataset(root_dir, data_file, 'val', use_rand_splits)\n",
    "test_data = MMDataset(root_dir, data_file, 'test', use_rand_splits)\n",
    "\n",
    "print(f'size of train set: {len(train_data)}, val set: {len(val_data)}, test set: {len(test_data)}')\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=bsz, shuffle=True, num_workers=12, collate_fn=MMDataset.mm_collate_fn)\n",
    "val_loader = DataLoader(val_data, batch_size=bsz, shuffle=False, num_workers=12, collate_fn=MMDataset.mm_collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=bsz, shuffle=False, num_workers=12, collate_fn=MMDataset.mm_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# init model (one of: MLPSTILClassifier, MLPSTILRegressor, Attention1DSTILClassifier, Attention1DSTILRegressor, Attention2DSTILClassifier, Attention2DSTILRegressor) \n",
    "model = Attention1DSTILRegressor(img_channels_in, text_channels_in)\n",
    "\n",
    "# set training args\n",
    "num_epochs = 50\n",
    "resume_ckpt = None\n",
    "args = {'num_epochs': num_epochs, 'ckpt_name': 'ckpt_best_def_split'}\n",
    "\n",
    "# train model\n",
    "model, trainer = train_mm_stil(model, train_loader, val_loader, args)\n",
    "\n",
    "# evaluate the trained model on the test set\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# run k-fold CV\n",
    "dataset = MMDataset()\n",
    "\n",
    "model_class = Attention1DSTILRegressor\n",
    "args = {'k': 5, 'num_epochs': 50, 'ckpt_name': 'ckpt_best_kfold_cv'}\n",
    "\n",
    "res_kfold_cv = kfold_cv(model_class, dataset, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg res over 5 folds: {'test_loss': 0.019, 'test_corr': 0.694, 'test_r2': 0.455}\n"
     ]
    }
   ],
   "source": [
    "metrics = ['test_loss', 'test_corr', 'test_r2']\n",
    "avg_res = {k: np.mean([res[k] for res in res_kfold_cv]).round(3) for k in metrics}\n",
    "print(f'avg res over {args['k']} folds: {avg_res}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
